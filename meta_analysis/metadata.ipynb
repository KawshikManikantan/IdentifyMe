{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from utils.get_processed_dataset import get_processed_dataset\n",
    "from utils.utils import read_jsonl, get_major_entities\n",
    "from omegaconf import OmegaConf\n",
    "from configs.config import PRONOUNS_GROUPS, PLURAL_PRONOUNS, dataset_yaml, selected_keys\n",
    "from configs.config_gen import NAME_TO_PREFIX\n",
    "from tqdm.auto import tqdm\n",
    "import hydra\n",
    "from utils.qa_utils import write_qa_to_jsonl, get_mention_info, add_copelands_count\n",
    "import dtale\n",
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import openai \n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path(__file__).resolve().parents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize(config_path=\"configs/args\")\n",
    "args = hydra.compose(config_name=\"args_qa.yaml\")\n",
    "\n",
    "# input_format_parts = [\"{{\", \"}} (#This is the marked mention)\"]\n",
    "# output_format_parts = [\"- Mention: \", \"- Explanation:\", \"- The mention refers to:\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_gender(dataset_proc_all, major_entities_all, doc_key):\n",
    "    pron_info = {}\n",
    "    gender_info = {}\n",
    "    for ind,entity_id in enumerate(major_entities_all[doc_key][\"entity_id\"]):\n",
    "        entity_mentions = dataset_proc_all[doc_key][\"clusters_vs_mentions\"][entity_id]\n",
    "        entity_mentions_str = [dataset_proc_all[doc_key][\"mentions_vs_mentionstr\"][mention].lower() for mention in entity_mentions]\n",
    "        entity_mentions_pro_grps = [PRONOUNS_GROUPS[mention] for mention in entity_mentions_str if mention in PRONOUNS_GROUPS]\n",
    "        counter_pro_grps = Counter(entity_mentions_pro_grps)\n",
    "        ## Convert to a set ordered by frequency of grps\n",
    "        counter_pro_grps = {k: v for k, v in sorted(counter_pro_grps.items(), key=lambda item: item[1], reverse=True)}\n",
    "        pron_info[major_entities_all[doc_key][\"entity_name\"][ind]] = counter_pro_grps\n",
    "        ## Determine the gender of the entity\n",
    "        gender_info[major_entities_all[doc_key][\"entity_name\"][ind]] = \"Unknown\"\n",
    "        for pro_grp in counter_pro_grps:\n",
    "            if pro_grp == 2:\n",
    "                gender_info[major_entities_all[doc_key][\"entity_name\"][ind]] = \"Male\"\n",
    "                break\n",
    "            elif pro_grp == 3:\n",
    "                gender_info[major_entities_all[doc_key][\"entity_name\"][ind]] = \"Female\"\n",
    "                break\n",
    "            elif pro_grp in [4,7]:\n",
    "                gender_info[major_entities_all[doc_key][\"entity_name\"][ind]] = \"Neutral\"\n",
    "                break\n",
    "\n",
    "    return pron_info, gender_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configs = OmegaConf.load(dataset_yaml)\n",
    "mention_info_df_final = pd.DataFrame()\n",
    "major_entities_all = {}\n",
    "dataset_proc_all = {}\n",
    "for dataset_name in [\"litbank\", \"fantasy\"]:\n",
    "    dataset_source = dataset_configs[dataset_name][f\"train_file\"]\n",
    "    tsv_addr = dataset_configs[dataset_name][f\"tsv\"]\n",
    "    doc_me = dataset_configs[dataset_name][f\"train_me\"]\n",
    "    dataset = read_jsonl(dataset_source)\n",
    "    dataset_proc = get_processed_dataset(dataset, tsv_litbank=tsv_addr)\n",
    "    dataset_proc_all.update(dataset_proc)\n",
    "    major_entities = get_major_entities(doc_me)\n",
    "    major_entities_all.update(major_entities)\n",
    "    mention_info_df = get_mention_info(dataset_proc, major_entities, tsv_addr=tsv_addr)\n",
    "    mention_info_df[\"dataset\"] = dataset_name\n",
    "    mention_info_df_final = pd.concat([mention_info_df_final, mention_info_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_gender_output(entity_name, doc_key):\n",
    "    load_dotenv()\n",
    "    prompt = f\"\"\"Classify the given phrase based on its gender. If the phrase clearly indicates a male name or title, classify it as 'Male.' If the phrase indicates a female name or title, classify it as 'Female.' If the phrase does not specify a male or female name/title, or it is ambiguous, classify it as 'Neutral.' The phrase may include titles, names, or other identifiers. Your options are: Male, Female, Neutral.\n",
    "\n",
    "Follow the format below:\n",
    "Explanation: \n",
    "Gender: \n",
    "\n",
    "The phrase is: \\\"\\\"\\\"{entity_name}\\\"\\\"\\\"\"\"\"\n",
    "    ## Create an api call to gpt-4o-mini\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    conversation = [{\"role\": \"user\", \"content\": prompt},]\n",
    "    output_string = \"\" \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=conversation,\n",
    "            temperature=0.0,\n",
    "            max_tokens=4095,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.content != None:\n",
    "                output_string += chunk.choices[0].delta.content\n",
    "            else:\n",
    "                finish_reason = chunk.choices[0].finish_reason\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Document ID: {doc_key} and Entity Name: {entity_name}\")\n",
    "        print(\"Error: \", e)\n",
    "        return {}\n",
    "\n",
    "    if finish_reason == \"content_filter\":\n",
    "        print(\"Content Filter Error in Document ID: {doc_key} and Entity Name: {entity_name}\")\n",
    "        print(f\"Content Filter Error: {completion}\")\n",
    "        return {}\n",
    "\n",
    "    if output_string != \"\":\n",
    "        predicted_answer = output_string.split(\"Gender:\")[-1].strip()\n",
    "        print(output_string)\n",
    "        return {\n",
    "            \"doc_key\": doc_key,\n",
    "            \"entity_name\": entity_name,\n",
    "            \"gender\": predicted_answer,\n",
    "            \"prompted\": True,\n",
    "            \"output_string\": output_string\n",
    "        }\n",
    "    \n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_info_list = []\n",
    "metadata_dest = \"data/metadata/gender_info.csv\"\n",
    "num_count = 0\n",
    "for document in tqdm(dataset_proc_all):\n",
    "    pron_info, gender_info = get_entity_gender(dataset_proc_all, major_entities_all, document)\n",
    "    for name in gender_info:\n",
    "        if gender_info[name] == \"Unknown\":\n",
    "            num_count += 1\n",
    "            gender_info_list.append(get_gpt_gender_output(name, document))\n",
    "        else:\n",
    "            gender_info_list.append(\n",
    "                {\n",
    "                    \"doc_key\": document,\n",
    "                    \"entity_name\": name,\n",
    "                    \"gender\": gender_info[name],\n",
    "                    \"prompted\": False,\n",
    "                    \"output_string\": \"N/A\"\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"Number of entities with unknown gender: {num_count}\")\n",
    "## Convert the list of dictionaries to a dataframe\n",
    "gender_info_df = pd.DataFrame(gender_info_list)\n",
    "## Save the dataframe to a csv\n",
    "gender_info_df.to_csv(metadata_dest, index=False)\n",
    "dtale.show(gender_info_df,subprocess=False,host='localhost', port=40001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_dialogue_output(text, doc_key, mention_ind):\n",
    "    load_dotenv()\n",
    "    prompt = f\"\"\"Read the text given below. The text has an entity mention marked within \\\"\\\"\\\" {{mention}} (#This is the marked mention) \\\"\\\"\\\". Extract the mention and the sentence it occurs. Determine if the sentence is a dialogue or part of a dialogue.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Follow the below format:\n",
    "- Mention:\n",
    "- Sentence:\n",
    "- Is the sentence a dialogue or part of dialogue: True/False\"\"\"\n",
    "\n",
    "    ## Create an api call to gpt-4o-mini\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    conversation = [{\"role\": \"user\", \"content\": prompt},]\n",
    "    output_string = \"\" \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=conversation,\n",
    "            temperature=0.0,\n",
    "            max_tokens=4095,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.content != None:\n",
    "                output_string += chunk.choices[0].delta.content\n",
    "            else:\n",
    "                finish_reason = chunk.choices[0].finish_reason\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Document ID: {doc_key} and Mention Ind: {mention_ind}\")\n",
    "        print(\"Error: \", e)\n",
    "        return {}\n",
    "\n",
    "    if finish_reason == \"content_filter\":\n",
    "        print(f\"Content Filter Error in Document ID: {doc_key} and Mention Ind: {mention_ind}\")\n",
    "        print(f\"Content Filter Error: {completion}\")\n",
    "        return {}\n",
    "\n",
    "    if output_string != \"\":\n",
    "        predicted_answer = output_string.split(\"Is the sentence a dialogue or part of dialogue:\")[-1].strip()\n",
    "        print(output_string)\n",
    "        print(f\"Predicted Answer: {predicted_answer == \"True\"}\")\n",
    "        return {\n",
    "            \"doc_key\": doc_key,\n",
    "            \"mention_ind\": mention_ind,\n",
    "            \"is_dialogue\": predicted_answer == \"True\",\n",
    "            \"output_string\": output_string\n",
    "        }\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_address = \"data/qas/data/qas_test.jsonl\"\n",
    "with jsonlines.open(dataset_address) as reader:\n",
    "    qa_data = list(reader)\n",
    "\n",
    "pron_dialogue_info = []\n",
    "metadata_dest = \"data/metadata/pron_dialogue_info.csv\"\n",
    "\n",
    "for obj in qa_data:\n",
    "    doc_key = obj[\"doc_key\"]\n",
    "    text = obj[\"text\"]\n",
    "    category = obj[\"category\"]\n",
    "    if category == \"PRON\":\n",
    "        pron_dialogue_info.append(get_gpt_dialogue_output(text, doc_key, obj[\"mention_ind\"]))\n",
    "\n",
    "## Convert the list of dictionaries to a dataframe\n",
    "pron_dialogue_info_df = pd.DataFrame(pron_dialogue_info)\n",
    "## Save the dataframe to a csv\n",
    "pron_dialogue_info_df.to_csv(metadata_dest, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(pron_dialogue_info_df,subprocess=False,host='localhost', port=40001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
